knitr::opts_chunk$set(echo = TRUE)
csv_path <- here("learning_journal_data.csv")
library(tidyverse)
library(here)
library(dataedu)
library(tidytext)
csv_path <- here("learning_journal_data.csv")
learning_journal <- read.csv(csv_path)
here::here()
learning_journal <- read_csv(here("Text Analytics", "learning_journal_data.csv"))
tokens <-
learning_journal %>%
unnest_tokens(output = word, input = Entries)
data(stop_words)
tokens <-
tokens %>%
anti_join(stop_words, by = "word")
head(tokens)
knitr::opts_chunk$set(echo = TRUE)
here::here()
lj_data <- read_csv(here("Social Network", "learning_journal_data1.csv"))
lj_data_original <- lj_data
# Tokenize the Summaries column
concepts <- lj_data %>%
unnest_tokens(word, Summaries)
# Remove duplicates
concepts <- concepts %>%
distinct(word)
head(concepts)
